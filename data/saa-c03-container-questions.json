[
    {
        "id": "ecs-q001",
        "type": "multiple-choice",
        "question": "A company wants to migrate an existing Docker-based microservice to AWS without managing servers. Each task needs 1 vCPU and 2 GiB of memory. Which launch type should the architect choose to minimize operational overhead?",
        "options": [
            "ECS EC2 launch type with t3.medium instances",
            "App Runner",
            "ECS Fargate",
            "EKS managed node group"
        ],
        "correctIndex": 2,
        "explanation": "Fargate is serverless for containers. You specify CPU and memory per task, and AWS provisions and scales the capacity. EC2 launch type and EKS require managing EC2 nodes. App Runner automatically builds and deploys from source or an image but does not support task-level IAM roles or service discovery like ECS.",
        "tags": [
            "Containers",
            "Performance"
        ]
    },
    {
        "id": "ecs-q002",
        "type": "multiple-choice",
        "question": "An ECS service running on EC2 launch type must access Amazon S3. What is the MOST secure way to grant access with least privilege?",
        "options": [
            "Embed AWS credentials in the container image",
            "Store credentials in ECS secrets and inject as environment variables",
            "Attach an S3 read policy to the instance profile role only",
            "Attach an S3 read policy to the task role and remove S3 permissions from the instance profile"
        ],
        "correctIndex": 3,
        "explanation": "The task role is intended for application-level permissions and is isolated per task. The instance profile is for the ECS agent and infrastructure operations. Hard-coding or injecting long-lived credentials is less secure.",
        "tags": [
            "Containers",
            "Security"
        ]
    },
    {
        "id": "ecs-q003",
        "type": "multiple-choice",
        "question": "An ECS cluster uses a capacity provider connected to an Auto Scaling group of spot instances. Tasks sometimes fail to launch due to insufficient memory even though CPU is available. What should be adjusted?",
        "options": [
            "Switch the capacity provider to on-demand instances only",
            "Use a capacity provider attribute for memory reservation and enable managed scaling",
            "Enable Service Discovery",
            "Scale out the Auto Scaling group using target-tracking on CPUUtilization"
        ],
        "correctIndex": 1,
        "explanation": "Capacity providers with managed scaling can evaluate both CPU and memory reservation. Adding the correct scaling metric for memory triggers instance provisioning when memory is constrained. CPU-only scaling does not solve memory shortages.",
        "tags": [
            "Compute",
            "Containers",
            "Resilience & DR"
        ]
    },
    {
        "id": "ecs-q004",
        "type": "multiple-choice",
        "question": "Which load balancer type is REQUIRED to distribute HTTP traffic to multiple ECS Fargate tasks running in private subnets and to perform path-based routing?",
        "options": [
            "Gateway Load Balancer",
            "Network Load Balancer",
            "Classic Load Balancer",
            "Application Load Balancer"
        ],
        "correctIndex": 3,
        "explanation": "ALB supports path-based routing and integrates with ECS service registries to register targets in private subnets. NLB is L4 and lacks path routing. CLB is legacy. Gateway LB is for appliance fleets.",
        "tags": [
            "Containers",
            "Performance",
            "VPC & Networking"
        ]
    },
    {
        "id": "ecs-q005",
        "type": "multiple-choice",
        "question": "A video processing task runs for several hours. Spot interruptions are acceptable but the task must gracefully stop. How can the architect detect when the task is stopped?",
        "options": [
            "Poll the ECS service every minute",
            "Subscribe to CloudWatch Logs filters",
            "Configure an EventBridge rule for the ECS Task State Change event with lastStatus = STOPPED",
            "Enable Container Insights"
        ],
        "correctIndex": 2,
        "explanation": "EventBridge emits Task State Change events. A rule can invoke SNS, Lambda, or Step Functions when lastStatus changes to STOPPED, enabling graceful workflows without polling.",
        "tags": [
            "Containers",
            "DevOps & Ops"
        ]
    },
    {
        "id": "ecs-q006",
        "type": "multiple-choice",
        "question": "Which storage option allows ECS Fargate tasks across multiple Availability Zones to share the same data volume concurrently?",
        "options": [
            "Amazon EBS",
            "Amazon EFS",
            "S3 mounted with s3fs",
            "Instance store"
        ],
        "correctIndex": 1,
        "explanation": "EFS is a regional, multi-AZ NFS file system and is supported natively by Fargate. EBS and instance store are single-AZ. Mounting S3 as a file system is unsupported and unreliable for POSIX workloads.",
        "tags": [
            "Containers",
            "Performance",
            "Storage"
        ]
    },
    {
        "id": "eks-q007",
        "type": "multiple-choice",
        "question": "An organization is standardizing on Kubernetes across clouds. They need managed control plane, spot worker nodes, and integration with IAM. Which combination delivers these requirements?",
        "options": [
            "App Runner with Terraform",
            "ECS Fargate with task roles",
            "Self-managed Kubernetes on EC2 using kops",
            "EKS with managed node groups and IAM Roles for Service Accounts (IRSA)"
        ],
        "correctIndex": 3,
        "explanation": "EKS offers managed control planes, managed node groups that can run spot instances, and IRSA for pod-level IAM. The other options do not meet all criteria.",
        "tags": [
            "Containers",
            "Resilience & DR",
            "Security"
        ]
    },
    {
        "id": "eks-q008",
        "type": "multiple-choice",
        "question": "In EKS Fargate profiles, which kubelet feature is NOT supported?",
        "options": [
            "Secrets",
            "DaemonSets",
            "ConfigMaps",
            "Horizontal Pod Autoscaler"
        ],
        "correctIndex": 1,
        "explanation": "Fargate runs each pod in its own micro-VM. DaemonSets require scheduling pods on every node, which is not compatible with the Fargate execution model. ConfigMaps, Secrets, and HPA are fully supported.",
        "tags": [
            "Containers",
            "Performance"
        ]
    },
    {
        "id": "eks-q009",
        "type": "multiple-choice",
        "question": "Which storage class and CSI driver should be used to provide dynamic, block-level persistent volumes with failover between AZs for an EKS StatefulSet?",
        "options": [
            "FSx for NetApp ONTAP CSI driver with Multi-AZ file system",
            "gp3 EBS CSI driver with single-AZ volumes",
            "EFS CSI driver with EFS One Zone",
            "io2 EBS Multi-Attach CSI driver with replication controllers"
        ],
        "correctIndex": 0,
        "explanation": "FSx ONTAP via CSI provides a shared file system across AZs with NFS/iSCSI, supporting failover and high performance. EBS volumes are single-AZ. Multi-Attach cannot span AZs safely for write-heavy workloads. EFS One Zone lacks AZ redundancy.",
        "tags": [
            "Containers",
            "Resilience & DR",
            "Storage"
        ]
    },
    {
        "id": "eks-q010",
        "type": "multiple-choice",
        "question": "A platform team wants to limit pod CPU usage cluster-wide in EKS. Which construct enforces default resource limits across namespaces?",
        "options": [
            "NetworkPolicy",
            "LimitRange",
            "HorizontalPodAutoscaler",
            "PodSecurityPolicy"
        ],
        "correctIndex": 1,
        "explanation": "LimitRange sets default CPU/memory requests and hard limits within a namespace. NetworkPolicy governs traffic, PodSecurityPolicy is deprecated in Kubernetes 1.25+, and HPA scales pods.",
        "tags": [
            "Containers",
            "Governance & Compliance",
            "Security"
        ]
    },
    {
        "id": "app-q011",
        "type": "multiple-choice",
        "question": "A developer pushes code to a GitHub repository. The company wants a fully managed runtime that automatically builds the container and scales HTTP traffic. Which service fits best?",
        "options": [
            "ECS Fargate with a CodePipeline build stage",
            "Lambda with container image deployment",
            "App Runner connected to the repository",
            "EKS with Argo CD"
        ],
        "correctIndex": 2,
        "explanation": "App Runner integrates directly with GitHub or ECR, performs automated builds, deploys, and scales a web service. ECS and EKS require manual pipelines. Lambda is event-driven and may not suit full HTTP servers with persistent connections.",
        "tags": [
            "DevOps & Ops"
        ]
    },
    {
        "id": "app-q012",
        "type": "multiple-choice",
        "question": "Which feature is unique to App Runner compared with ECS Fargate web services?",
        "options": [
            "Auto scaling based on concurrent requests",
            "Auto TLS certificate provisioning and HTTPS endpoint",
            "IAM roles for containers",
            "Private VPC access via VPC connectors"
        ],
        "correctIndex": 1,
        "explanation": "App Runner automatically provisions TLS certificates and exposes an HTTPS URL without extra configuration. ECS requires an ALB and ACM certificate. Both services support VPC access, IAM roles, and scaling.",
        "tags": [
            "Performance",
            "Security"
        ]
    },
    {
        "id": "a2c-q013",
        "type": "multiple-choice",
        "question": "App2Container is used to containerize a legacy .NET MVC application running on Windows Server 2012. What is a REQUIRED output before deployment?",
        "options": [
            "A Dockerfile and container image in ECR",
            "An AMI with the application pre-installed",
            "An AWS CloudFormation template describing ECS resources",
            "A Helm chart for Kubernetes"
        ],
        "correctIndex": 0,
        "explanation": "App2Container creates a Dockerfile and builds an image pushed to ECR. It can optionally generate CloudFormation or ECS task definitions, but the image is required for any deployment target.",
        "tags": [
            "Containers",
            "Resilience & DR"
        ]
    },
    {
        "id": "ecs-q014",
        "type": "multiple-choice",
        "question": "An ECS service running on Fargate must scale based on the number of visible messages in an SQS queue. Which two AWS services are REQUIRED?",
        "options": [
            "Auto Scaling group and Step Scaling",
            "Application Auto Scaling and CloudWatch alarms",
            "Lambda scheduled polling and EventBridge",
            "Service Discovery and Route 53"
        ],
        "correctIndex": 1,
        "explanation": "Application Auto Scaling supports target-tracking on Amazon SQS metrics. CloudWatch provides the ApproximateNumberOfMessagesVisible metric and the alarm triggers scaling policies.",
        "tags": [
            "Compute",
            "Containers",
            "Cost Optimization",
            "Integration & Messaging"
        ]
    },
    {
        "id": "eks-q015",
        "type": "multiple-choice",
        "question": "Which authentication mechanism allows Kubernetes pods in EKS to assume distinct IAM roles without sharing node instance profiles?",
        "options": [
            "Kubernetes service accounts mapped to IAM roles via OIDC",
            "AWS STS GetSessionToken on each container start",
            "Kube-RBAC authentication webhook",
            "Static credentials mounted as secrets"
        ],
        "correctIndex": 0,
        "explanation": "IAM Roles for Service Accounts (IRSA) uses an OIDC identity provider to map a Kubernetes service account to an IAM role. Nodes keep a minimal instance profile, and each pod gets fine-grained permissions.",
        "tags": [
            "Containers",
            "Security"
        ]
    },
    {
        "id": "eks-q016",
        "type": "multiple-choice",
        "question": "A production EKS cluster needs zero-downtime version upgrades. Which AWS-provided component simplifies the rolling replacement of control plane and managed node groups?",
        "options": [
            "eksctl upgrade cluster",
            "Elastic Beanstalk managed updates",
            "ECS blue/green deploy",
            "kubeadm upgrade"
        ],
        "correctIndex": 0,
        "explanation": "The eksctl CLI orchestrates control-plane updates and can automatically create new managed node groups with the target Kubernetes version, drain old nodes, and promote new ones with no downtime.",
        "tags": [
            "Containers",
            "DevOps & Ops"
        ]
    },
    {
        "id": "ecs-q017",
        "type": "multiple-choice",
        "question": "A security team mandates that all container images used by ECS be scanned for vulnerabilities before deployment. Which service or feature helps automate this requirement?",
        "options": [
            "Inspector Classic host assessment",
            "CloudFront signed URLs",
            "Amazon ECR image scanning with AWS Security Hub integration",
            "AWS GuardDuty"
        ],
        "correctIndex": 2,
        "explanation": "ECR provides native image scanning (basic or enhanced) and can be integrated with Security Hub for compliance. Inspector Classic scans EC2 instances, not images. GuardDuty detects threats in logs, not image CVEs. CloudFront is unrelated.",
        "tags": [
            "Containers",
            "Security"
        ]
    },
    {
        "id": "eks-q018",
        "type": "multiple-choice",
        "question": "Which networking add-on is required to enable Kubernetes NetworkPolicy enforcement in EKS without third-party plugins?",
        "options": [
            "Calico policy engine",
            "kube-proxy in IPVS mode",
            "Cilium eBPF plugin",
            "Amazon VPC CNI with security group for pods"
        ],
        "correctIndex": 0,
        "explanation": "Calico is supported by AWS as an optional add-on to enforce Kubernetes NetworkPolicy on EKS clusters. The default VPC CNI does not interpret NetworkPolicy. Cilium is possible but community managed. kube-proxy handles service routing, not policies.",
        "tags": [
            "Containers",
            "Security",
            "VPC & Networking"
        ]
    },
    {
        "id": "app-q019",
        "type": "multiple-choice",
        "question": "App Runner services must connect to an RDS database in a private subnet. Which configuration is NECESSARY?",
        "options": [
            "Use environment variables to store database password only",
            "Enable public access for the RDS instance",
            "Add a Kubernetes ingress controller",
            "Create a VPC connector in App Runner and reference it in the service"
        ],
        "correctIndex": 3,
        "explanation": "App Runner needs a VPC connector to establish ENIs in a private subnet for outbound traffic to RDS. Making RDS public violates security. Ingress controllers are EKS concepts. Environment variables store secrets but do not enable network reachability.",
        "tags": [
            "Security",
            "VPC & Networking"
        ]
    },
    {
        "id": "a2c-q020",
        "type": "multiple-choice",
        "question": "During App2Container analysis, which prerequisite must be met on the source Windows server?",
        "options": [
            "Kubernetes kubelet agent installed",
            "Docker Desktop installed and running",
            "Hyper-V disabled",
            "Administrator PowerShell access and .NET Framework 4.7.2 or later"
        ],
        "correctIndex": 3,
        "explanation": "App2Container requires admin rights to inspect IIS, read registry, and package binaries. It depends on .NET for analysis scripts. Docker is not needed on the source machine.",
        "tags": [
            "Resilience & DR"
        ]
    },
    {
        "id": "ecs-q021",
        "type": "open-ended",
        "question": "Describe how ECS rolling updates work in a service using CodeDeploy blue/green deployments and explain two advantages over the default rolling update strategy.",
        "answer": "When integrated with CodeDeploy, ECS creates a new task set (green) alongside the existing one (blue). CodeDeploy shifts a configurable percentage of traffic through an ALB listener to the green tasks, monitors CloudWatch alarms and container health, and continues shifting until 100 % or rolls back automatically. Advantages: (1) zero-downtime testing with real production traffic on a small subset before full cutover, reducing risk; (2) automatic rollback if alarms breach, avoiding manual intervention required with default rolling where tasks are replaced incrementally without traffic controls.",
        "tags": [
            "Containers",
            "Resilience & DR"
        ]
    },
    {
        "id": "eks-q022",
        "type": "open-ended",
        "question": "Explain the security benefits of using IAM Roles for Service Accounts (IRSA) in EKS and outline the high-level steps to enable it for a pod that needs to access Amazon S3.",
        "answer": "IRSA maps a Kubernetes service account to a dedicated IAM role using the cluster\u2019s OIDC provider, eliminating the need to distribute node-wide credentials. Each pod receives a signed token projected into the file system, which AWS STS validates before issuing temporary credentials scoped by the role policy. Steps: 1) Enable the OIDC provider in the EKS console or eksctl. 2) Create an IAM role with trust policy referencing the provider and condition on the service account name/namespace. 3) Attach an S3 access policy to the role. 4) Create a Kubernetes service account annotated with the role ARN. 5) Reference that service account in the pod spec. The pod now uses least-privilege, short-lived credentials to call S3.",
        "tags": [
            "Containers",
            "Security"
        ]
    },
    {
        "id": "app-q023",
        "type": "open-ended",
        "question": "Compare App Runner and ECS Fargate for stateless web applications in terms of deployment workflow, scaling controls, and cost transparency.",
        "answer": "App Runner abstracts the infrastructure: developers push code or an image, and App Runner builds, deploys, auto provisions TLS, and scales instances based on concurrent requests. Scaling is automatic with min/max instance settings but less granular than Fargate task counts. Pricing is per vCPU-sec and memory-sec for running instances plus build minutes. ECS Fargate requires a task definition and service; deployment pipelines (e.g., CodePipeline) must build images separately. Fargate scales by changing desired task count via Application Auto Scaling policies; it offers fine control over CPU/memory per task. Costs are transparent per task-hour but you manage load balancers and CI/CD. App Runner is simpler; Fargate is more flexible and can be cheaper at very low or very high loads depending on configuration.",
        "tags": [
            "Containers",
            "Cost Optimization"
        ]
    },
    {
        "id": "a2c-q024",
        "type": "open-ended",
        "question": "Outline an end-to-end migration path using App2Container to move an on-premises Java Spring Boot application to AWS EKS, including CI/CD considerations.",
        "answer": "1) Install App2Container on the source server, analyze the running Spring Boot process, and generate a Dockerfile. 2) Use App2Container to build the image and push to ECR. 3) Generate the Kubernetes deployment YAML and service manifest. 4) Commit the manifests to a Git repository. 5) Create a build pipeline (CodeBuild or Jenkins) to rebuild the image on code changes and update the tag in a Helm chart. 6) Use CodePipeline or Argo CD to deploy to an EKS namespace, leveraging blue/green strategy via a Kubernetes service. 7) Enable IRSA for S3/Secrets access, configure the ALB Ingress Controller, and set HPA for scaling. 8) Monitor with Container Insights and set CloudWatch alarms. This pipeline provides automated build, containerization, and continuous delivery on managed Kubernetes.",
        "tags": [
            "Containers",
            "Resilience & DR"
        ]
    }
]